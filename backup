package node

import (
	"encoding/json"
	"fmt"
	"log"
	"net"
	"os"
	"os/signal"
	"strconv"
	"strings"
	"syscall"
	"time"

	"ProgettoSDCC/pkg/proto"
)

type Node struct {
	PeerMgr  *PeerManager
	Registry *ServiceRegistry
	Digests  *DigestManager
	GossipM  *GossipManager
	FailureD *FailureDetector
	ID       string
	Port     int

	// rumor tracking for quorum-based failure detector
	suspectCount    map[string]int  // peer → numero di rumor sospetti visti
	seenSuspect     map[string]bool // rumorID sospetti già visti
	seenDead        map[string]bool // rumorID dead già visti
	quorumThreshold int             // soglia di quorum per confermare dead
	initialSeeds    []string        // i seed passati in --peers
	seenLeave       map[string]bool // peer → già processato Leave

	udpConn      *net.UDPConn
	done         chan struct{}
	gossipTicker *time.Ticker
}

func hasDeadRumorsFor(peer string, seenDead map[string]bool) bool {
	prefix := "dead|" + peer + "|"
	for id := range seenDead {
		if strings.HasPrefix(id, prefix) {
			return true
		}
	}
	return false
}

func NewNodeWithID(id, peerCSV, svcCSV string) *Node {
	parts := strings.Split(id, ":")
	if len(parts) != 2 {
		log.Fatalf("invalid id %s", id)
	}
	port, err := strconv.Atoi(parts[1])
	if err != nil {
		log.Fatalf("bad port: %v", err)
	}

	seeds := strings.Split(peerCSV, ",")
	pm := NewPeerManager(seeds, id)
	reg := NewServiceRegistry()
	reg.AddLocal(id, svcCSV)

	dm := NewDigestManager()
	gm := NewGossipManager(pm, dm, reg, id)

	// quorumThreshold iniziale verrà calcolato da updateQuorum()
	quorum := 0
	// FailureDetector ora accetta gossip manager e due timeout
	fd := NewFailureDetector(pm, reg, gm, 15*time.Second, 20*time.Second)

	n := &Node{
		PeerMgr:  pm,
		Registry: reg,
		Digests:  dm,
		GossipM:  gm,
		FailureD: fd,
		ID:       id,
		Port:     port,

		suspectCount:    make(map[string]int),
		seenSuspect:     make(map[string]bool),
		seenDead:        make(map[string]bool),
		quorumThreshold: quorum,
		initialSeeds:    seeds,
		seenLeave:       make(map[string]bool),
	}
	// calcola il quorum basato su peer iniziali + me
	n.updateQuorum()
	return n
}

// conta i peer "alive" basandosi su LastSeen entro failTimeout
func (n *Node) alivePeerCount() int {

	n.PeerMgr.mu.Lock()
	defer n.PeerMgr.mu.Unlock()
	now := time.Now()
	cnt := 0
	for _, ts := range n.PeerMgr.LastSeen {
		if now.Sub(ts) <= n.FailureD.failTimeout {
			cnt++
		}
	}
	return cnt
}

// aggiorna quorumThreshold in base al numero di peer "alive" + nodo locale
func (n *Node) updateQuorum() {
	size := n.alivePeerCount() + 1 // includi me
	n.quorumThreshold = size/2 + 1
}

// restituisce la slice degli indirizzi dei peer "alive"
func (n *Node) alivePeers() []string {
	n.PeerMgr.mu.Lock()
	defer n.PeerMgr.mu.Unlock()
	now := time.Now()
	var out []string
	for peer, ts := range n.PeerMgr.LastSeen {
		if now.Sub(ts) <= n.FailureD.failTimeout {
			out = append(out, peer)
		}
	}
	return out
}

func (pm *PeerManager) AddIfNew(peer string) {
	pm.mu.Lock()
	defer pm.mu.Unlock()
	if !pm.Peers[peer] {
		pm.Peers[peer] = true
		pm.LastSeen[peer] = time.Now()
	}
}

func (n *Node) Shutdown() {
	log.Printf("→ Shutdown: propago Leave e chiudo tutto…")

	// 1) invia MsgLeave
	lv := proto.Leave{Peer: n.ID}
	pkt, _ := proto.Encode(proto.MsgLeave, n.ID, lv)
	for _, p := range n.PeerMgr.List() {
		n.GossipM.SendUDP(pkt, p)
	}

	// 2) dai tempo al pacchetto UDP di partire
	time.Sleep(500 * time.Millisecond)

	// 3) ferma ticker e goroutine
	n.gossipTicker.Stop()
	close(n.done)

	// 4) chiudi socket UDP
	n.udpConn.Close()

	// 5) (opzionale) aspetta un po’ per essere sicuro…
	time.Sleep(100 * time.Millisecond)
}

func (n *Node) Run(lookupSvc string) {

	// 1. intercetta SIGTERM/SIGINT
	sigCh := make(chan os.Signal, 1)
	signal.Notify(sigCh, syscall.SIGINT, syscall.SIGTERM)
	go func() {
		<-sigCh
		log.Printf("→ received SIGTERM/SIGINT, sending Leave…")
		lv := proto.Leave{Peer: n.ID}
		pkt, _ := proto.Encode(proto.MsgLeave, n.ID, lv)
		for _, p := range n.PeerMgr.List() {
			// qui sendUDP è visibile perché siamo nel package node
			n.GossipM.SendUDP(pkt, p)
		}
		time.Sleep(500 * time.Millisecond)

		os.Exit(0)
	}()
	// 1. Avvia gossip e failure detector
	n.GossipM.Start()
	n.FailureD.Start()

	// 1.b) Log periodico dello stato cluster/quorum
	go func() {
		tick := time.NewTicker(10 * time.Second)
		defer tick.Stop()
		for range tick.C {
			peers := n.alivePeers()
			aliveCount := len(peers) + 1 // +1 = me
			log.Printf(">> Cluster alive=%d  quorum=%d  peers=%v", aliveCount, n.quorumThreshold, peers)
		}
	}()

	// 2. Apri socket UDP
	addr := &net.UDPAddr{Port: n.Port, IP: net.IPv4zero}
	conn, err := net.ListenUDP("udp", addr)
	if err != nil {
		log.Fatalf("ListenUDP: %v", err)
	}
	defer conn.Close()

	// 3. Goroutine di lettura gossip e lookup
	done := make(chan struct{})
	go func() {
		buf := make([]byte, 4096)
		for {
			select {
			case <-done:
				return
			default:
				nRead, srcAddr, err := conn.ReadFromUDP(buf)
				if err != nil {
					if strings.Contains(err.Error(), "closed network connection") {
						return
					}
					log.Printf("ReadUDP: %v", err)
					continue
				}
				env, err := proto.Decode(buf[:nRead])
				if err != nil {
					continue
				}

				switch env.Type {

				case proto.MsgHeartbeat, proto.MsgHeartbeatDigest:

					var hb proto.Heartbeat
					if json.Unmarshal(env.Data, &hb) == nil {
						peer := env.From

						for _, p2 := range hb.Peers {
							if p2 != n.ID {
								n.PeerMgr.AddIfNew(p2)
							}
						}

						if n.seenLeave[peer] {
							// era uscito volontariamente, ora sta tornando
							delete(n.seenLeave, peer)
							log.Printf("Peer %s RI-ENTRATO (dopo leave)", peer)
						}
						// se era già “morto”, pulisco solo il suo stato rumor
						if n.suspectCount[peer] > 0 || hasDeadRumorsFor(peer, n.seenDead) {
							// cancello tutti i suspectID di quel peer
							for id := range n.seenSuspect {
								if strings.HasPrefix(id, "suspect|"+peer+"|") {
									delete(n.seenSuspect, id)
								}
							}
							// cancello tutti i deadID di quel peer
							for id := range n.seenDead {
								if strings.HasPrefix(id, "dead|"+peer+"|") {
									delete(n.seenDead, id)
								}
							}
							n.suspectCount[peer] = 0
							log.Printf("Peer %s RI-ENTRATO: resetto failure-detector", peer)

						}

						n.PeerMgr.Add(peer)
						n.updateQuorum()
						n.PeerMgr.Seen(peer)
						n.Registry.Update(peer, hb.Services)
						log.Printf(
							"HB from %-12s services=%v digest=%s peers=%v",
							peer,
							hb.Services,
							hb.Digest,
							hb.Peers, // <<< ora vediamo il tuo piggy-back
						)
					}

				case proto.MsgRumor:
					// TODO: rumor handling

				case proto.MsgLookup:
					lr, err := proto.DecodeLookupRequest(env.Data)
					if err != nil {
						log.Printf("bad LookupRequest: %v", err)
						continue
					}
					log.Printf("RX Lookup %s TTL=%d from %s", lr.Service, lr.TTL, env.From)

					// se ho il servizio, rispondo direttamente
					if provider, ok := n.Registry.Lookup(lr.Service); ok {
						resp := proto.LookupResponse{ID: lr.ID, Provider: provider}
						out, err := proto.Encode(proto.MsgLookupResponse, n.ID, resp)
						if err == nil {
							conn.WriteToUDP(out, srcAddr)
							log.Printf("  -> replied to %s", srcAddr)
						}
						continue
					}

					// forward se TTL>0
					if lr.TTL > 0 {
						lr.TTL--
						out, err := proto.Encode(proto.MsgLookup, n.ID, lr)
						if err == nil {
							for _, p := range n.PeerMgr.List() {
								if p == env.From {
									continue
								}
								n.GossipM.SendUDP(out, p)
							}
							log.Printf("  -> forwarded TTL=%d", lr.TTL)
						}
					}

				case proto.MsgLookupResponse:
					lrsp, err := proto.DecodeLookupResponse(env.Data)
					if err == nil {
						log.Printf("RX LookupResponse %s → %s", lrsp.ID, lrsp.Provider)
					}

				case proto.MsgSuspect:
					// 1) decodifica e dedup
					r, err := proto.DecodeSuspectRumor(env.Data)
					if err != nil || n.seenSuspect[r.RumorID] {
						break
					}
					n.seenSuspect[r.RumorID] = true

					// 2) incremento il conteggio dei sospetti per quel peer
					n.suspectCount[r.Peer]++

					// 3) rilancio sempre il SuspectRumor a tutti i peer
					outS, _ := proto.Encode(proto.MsgSuspect, n.ID, r)
					for _, p := range n.PeerMgr.List() {
						n.GossipM.SendUDP(outS, p)
					}

					// 4) appena raggiungi il quorum (2), logga e genera il DeadRumor
					if n.suspectCount[r.Peer] == n.quorumThreshold {
						log.Printf("Peer %s DEAD (quorum %d raggiunto)", r.Peer, n.quorumThreshold)

						d := proto.DeadRumor{
							RumorID: fmt.Sprintf("dead|%s|%d", r.Peer, time.Now().UnixNano()),
							Peer:    r.Peer,
						}
						outD, _ := proto.Encode(proto.MsgDead, n.ID, d)
						for _, p := range n.PeerMgr.List() {
							n.GossipM.SendUDP(outD, p)
						}
						// rimuovo il provider una sola volta
						n.Registry.RemoveProvider(r.Peer)
						n.updateQuorum()
					}

				case proto.MsgDead:
					d, err := proto.DecodeDeadRumor(env.Data)
					if err != nil || n.seenDead[d.RumorID] {
						break
					}
					n.seenDead[d.RumorID] = true
					log.Printf("Peer %s DEAD (ricevuto rumor %s)", d.Peer, d.RumorID)
					// rilancio dead rumor
					outD, _ := proto.Encode(proto.MsgDead, n.ID, d)
					for _, p := range n.PeerMgr.List() {
						n.GossipM.SendUDP(outD, p)
					}
					// già dopo il tuo log “Peer X DEAD…”
					n.PeerMgr.Remove(d.Peer)
					n.Registry.RemoveProvider(d.Peer)
					n.updateQuorum()
				case proto.MsgLeave:
					lv, err := proto.DecodeLeave(env.Data)
					if err != nil {
						log.Printf("bad Leave payload: %v", err)
						break
					}
					peer := lv.Peer

					// se l'abbiamo già visto, ignora
					if n.seenLeave[peer] {
						break
					}
					n.seenLeave[peer] = true

					log.Printf("Peer %s → LEFT voluntarily", peer)

					// propaga una sola volta
					raw, _ := proto.Encode(proto.MsgLeave, n.ID, lv)
					for _, p := range n.PeerMgr.List() {
						if p != env.From {
							n.GossipM.SendUDP(raw, p)
						}
					}

					// pulizia definitiva
					n.PeerMgr.Remove(peer)
					n.Registry.RemoveProvider(peer)
					n.updateQuorum()
				default:
					log.Printf("unknown msg type %d", env.Type)
				}
			}
		}
	}()

	// 4. Fallback al lookup storico
	if lookupSvc != "" {
		log.Printf("Waiting for heartbeats before lookup…")
		time.Sleep(8 * time.Second)

		if p, ok := n.Registry.Lookup(lookupSvc); ok {
			fmt.Printf("Service %s → %s", lookupSvc, p)
		} else {
			fmt.Printf("Service %s NOT found", lookupSvc)
		}

		close(done)
		conn.Close()
		return
	}

	// 5. Nodo normale: non esce mai
	select {}
}
